# config from original paper
learning_rate: 0.0002
batch_size: 128
epochs: 100
optimizer: Adam
criterion: BCELoss
image_size: 64
dataset: celebA
model:
  name: CDCGAN
  parameters:
    beta1: 0.5
    dropout: 0.0
    use_spectral_norm: False
    ngf: 64
    ndf: 64
    z_channels: 128
device: cpu # (cuda / cpu / auto)
experiment_path: ..\experiments
frequencies:
  save_freq: 1 # (i.e. how often should the model checkpoint be saved, in epochs)
  gen_freq: 1 # (i.e. how often should test images be generated, in epochs)