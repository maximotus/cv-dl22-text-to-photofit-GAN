mode: train
log_level: 20
device: cpu
experiment_path: ..\experiments
epochs: 500
num_imgs: 20
predefined_images: {max: [0,0,1,1,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,1,1,1,0,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,0,1], daniel: [0,1,1,1,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,1,1,0,0,1,0,1,0,1,0,0,1,0,0,0,0,0,0,0,1]}

frequencies:
  save_freq: 1
  gen_freq: 1

dataloader:
  dataset: celebA
  size_fraction: 50000
  batch_size: 1
  image_size: 64

model:
  name: CDCGAN
  pretrained_path: ../experiments/train/template-CDCGAN-train/2022-08-08-17-07-12 # use pretrained model checkpoint to continue training from
  start_epoch: 3 # specify epoch from which to continue training
  criterion: BCELoss
  optimizer: Adam
  learning_rate: 0.001
  parameters:
    dropout: 0.2
    alpha: 0.1
    beta1: 0.1
    ngf: 64
    ndf: 64
    z_channels: 128
    use_spectral_norm: False
